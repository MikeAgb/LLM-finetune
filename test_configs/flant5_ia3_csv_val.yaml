model:
  model_name: "t5-small"
  model_config:
  quant_config:
    load_in_4bit: true
    bnb_4bit_quant_type: "nf4"
    bnb_4bit_use_double_quant: true
    bnb_4bit_compute_dtype: "torch.bfloat16"
task_type: "SEQ_2_SEQ_LM"
peft:
  type: "ia3"
  peft_config:
    target_modules:
      - q
      - v
data:
  data_location: "local"
  train_data: "seq_2_seq_train.csv"
  eval_data:
token:
  max_length: 128
  truncation: true
  padding: "max_length"
train:
  type: "trainer"
  final_save_path: "./"
  train_config:
    per_device_train_batch_size: 1
    learning_rate: 0.0001
    gradient_accumulation_steps: 4
    save_steps: 1
    logging_steps: 1
    max_grad_norm: 1
    num_train_epochs: 5
    warmup_ratio: 0.03
    lr_scheduler_type: "constant"
    report_to: 
    disable_tqdm: true
    group_by_length: true
    fp16: true
    optim: "adamw_bnb_8bit"



